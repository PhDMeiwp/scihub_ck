# 20180307
## 版本
version 1.0.5.20180303_alpha

## 感想
版本稳定了就停止开发了吗？不。这不只是一个实用便利的工具，也是我技能综合运用的体现，以及未来学习方向的指引。

## 功能
相较于上一个稳定版本1.0.0.20180201_alpha，本版本有以下几点功能完善：
1. 运行提速：由最初的40-60分钟耗时，通过几个版本的优化，缩短到现在不到20秒
2. 周期缩短：受限于运行耗时，网站更新周期原先只能2小时一次，现在提升到每分钟一次，24小时不间断
3. 稳定性提高：过年期间稳定运行了20天，年后回来连着网站挂了3次，有时不在机器旁边无法维护，一狠心买了五年云服务器，把代码从天天担心着火的树莓派搬到了阿里云，只要有网络可以随时维护，无需担心断网断电
4. 策略改进：大改了代码和列表文件，发现没有必要每次都把262个域名都遍历，scihub也不是每分钟都换域名，全部域名的遍历每天一次就好，所以定在了每天睡觉人最多的凌晨4点进行全部域名的遍历，检测当天能用的域名地址，之后就是每分钟检测大约10-12个域名的速度，去除了其他多余的代码块，加了一些运行进程的提示

## 问题
问题仍然有：
1. 3月5日发现hk和ws失效，发生在全域名检测之后，于是后续每次快速检测都没剔除这两个域名，还需要加深对curl的理解，之后加个条件句，严谨一下，不过这类问题在第二天全域名检测后就不存在了
2. 全域名检测有的时候会漏掉个别很慢的域名，因为限时3秒钟响应，慢一次不代表次次慢，后续可以多进行几次全域名检测，然后汇总一下，确保当天信息最全
3. 服务器在新加坡，新加坡对于各网站响应的速度只能代表新加坡，不能代表国内，有的网站国外能访问，国内不一定，所以有时点开排名第二的域名反而比第一还快，秒开，不过排名最后的在国内也确实还是最后，有点误差但也不是差很大
4. 现在判断网站是否为真网站的方法简单粗暴，就看文件大小是不是26860b，后续还需要严谨一点，多设置几种checkpoint，以防恶意网站
5. 前端设计有冗余代码，还有不必要的样式引用，访问耗时也要1秒钟，移动端自适应也不够友好，考虑套用github自带的模版会不会好些

## 计划
1. 加强前端知识，简化美化网页
2. 加强curl理解，完善域名有效性判断
3. 加强js理解，增加数据可视化展示
4. 加强c理解，重写代码
5. 加强数据库理解，增加数据库支持

## 感想
scihub_ck的更新到现在基本稳定了，后续一段时间（数月）也多数是一些小问题的日常维护，再较大幅度的提升，就需要新的技能积累了。下一步可能是一个更炫酷的页面，或者详尽的数据分析展示，或者更迅速的程序，或者后台稳定的数据库支持。
